{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader ,Dataset\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2D_f = pd.read_csv(\"../Data/Microbiome_data/T2D_data/T2D_fuctional.csv\",sep=\",\")\n",
    "T2D_tax = pd.read_csv(\"../Data/Microbiome_data/T2D_data/T2D_taxo.csv\",sep=\",\")\n",
    "T2D_gen = pd.read_csv(\"../Data/Microbiome_data/T2D_data/T2D_gen40.csv\",sep=\",\")\n",
    "T2D_labels = pd.read_csv(\"../Data/Microbiome_data/T2D_data/T2D_ylab.txt\")\n",
    "T2D_labels= T2D_labels.iloc[:-1]\n",
    "T2D_labels = T2D_labels[:].values\n",
    "T2D_labels= pd.DataFrame(T2D_labels)\n",
    "T2D_labels = T2D_labels.replace({\"Control\": 1, \"T2D\": 0})\n",
    "\n",
    "CRC_f = pd.read_csv(\"../Data/Microbiome_data/CRC_data/CRC_Fuctional.csv\",sep=\",\")\n",
    "CRC_tax = pd.read_csv(\"../Data/Microbiome_data/CRC_data/CRC_Taxo.csv\",sep=\",\")\n",
    "CRC_gen = pd.read_csv(\"../Data/Microbiome_data/CRC_data/CRC_gen40.csv\",sep=\",\")\n",
    "CRC_labels = pd.read_csv(\"../Data/Microbiome_data/CRC_data/CRC_ylab.txt\")\n",
    "CRC_labels= CRC_labels.iloc[:-1]\n",
    "CRC_labels = CRC_labels[:].values\n",
    "CRC_labels= pd.DataFrame(CRC_labels)\n",
    "CRC_labels = CRC_labels.replace({\"control\": 1, \"CRC\": 2})\n",
    "\n",
    "IBD_f = pd.read_csv(\"../Data/Microbiome_data/IBD_data/IBD_fuctional.csv\",sep=\",\")\n",
    "IBD_tax = pd.read_csv(\"../Data/Microbiome_data/IBD_data/IBD_taxo.csv\",sep=\",\")\n",
    "IBD_gen = pd.read_csv(\"../Data/Microbiome_data/IBD_data/IBD_gen40.csv\",sep=\",\")\n",
    "IBD_labels = pd.read_csv(\"../Data/Microbiome_data/IBD_data/IBD_ylab.txt\")\n",
    "IBD_labels= IBD_labels.iloc[:-1]\n",
    "IBD_labels = IBD_labels[:].values\n",
    "IBD_labels= pd.DataFrame(IBD_labels)\n",
    "IBD_labels = IBD_labels.replace({\"Normal\": 1, \"IBD\": 3})\n",
    "\n",
    "\n",
    "LC_f = pd.read_csv(\"../Data/Microbiome_data/LC_data/LC_Fuctional.csv\",sep=\",\")\n",
    "LC_tax = pd.read_csv(\"../Data/Microbiome_data/LC_data/LC_taxo.csv\",sep=\",\")\n",
    "LC_gen = pd.read_csv(\"../Data/Microbiome_data/LC_data/LC_gen40.csv\",sep=\",\")\n",
    "LC_labels = pd.read_csv(\"../Data/Microbiome_data/LC_data/LC_ylab.txt\")\n",
    "LC_labels= LC_labels.iloc[:-1]\n",
    "LC_labels = LC_labels[:].values\n",
    "LC_labels= pd.DataFrame(LC_labels)\n",
    "LC_labels = LC_labels.replace({\"Normal\": 1, \"Cirrhosis\": 4})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = torch.tensor(T2D_f.values)\n",
    "f2 = torch.tensor(T2D_gen.values)\n",
    "f3 = torch.tensor(T2D_tax.values)\n",
    "f4 = torch.tensor(IBD_f.values)\n",
    "f5 = torch.tensor(IBD_gen.values)\n",
    "f6 = torch.tensor(IBD_tax.values)\n",
    "f7= torch.tensor(CRC_f.values)\n",
    "f8 = torch.tensor(CRC_gen.values)\n",
    "f9= torch.tensor(CRC_tax.values)\n",
    "f10 = torch.tensor(LC_f.values)\n",
    "f11= torch.tensor(LC_gen.values)\n",
    "f12 = torch.tensor(LC_tax.values)\n",
    "\n",
    "l1 = torch.tensor(T2D_labels.values)\n",
    "l2 = torch.tensor(IBD_labels.values)\n",
    "l3 = torch.tensor(CRC_labels.values)\n",
    "l4 = torch.tensor(LC_labels.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "T2D_comb = torch.cat((f1,f2,f3), dim=1)\n",
    "IBD_comb = torch.cat((f4,f5,f6), dim=1)\n",
    "CRC_comb = torch.cat((f7,f8,f9), dim=1)\n",
    "LC_comb = torch.cat((f10,f11,f12), dim=1)\n",
    "compined = torch.cat((T2D_comb,IBD_comb,CRC_comb,LC_comb))\n",
    "\n",
    "labels_combined = torch.cat((l1,l2,l3,l4))\n",
    "\n",
    "Test1 = torch.cat((f2,f5,f8,f11))\n",
    "TestL= torch.cat((l2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save it to tensor .pt objects\n",
    "torch.save(labels_combined, '../Data/Tensors_objs/labels.pt')\n",
    "torch.save(compined, '../Data/Tensors_objs/features.pt')\n",
    "np.savetxt(\"test\",Test1,delimiter =\",\")\n",
    "np.savetxt(\"TestL\",TestL,delimiter=\",\")\n",
    "np.savetxt(\"Data\", compined, delimiter=\",\")\n",
    "np.savetxt(\"Labels\", labels_combined, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Load your data into a numpy array called X\n",
    "X = np.loadtxt(\"test\", delimiter=\",\")\n",
    "y = np.loadtxt(\"Labels\")\n",
    "\n",
    "# Separate your class labels from your feature data\n",
    "\n",
    "\n",
    "# Apply PCA to reduce the dimensionality of your data to 2 dimensions\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Plot your data in 2 dimensions, colored by class label\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y)\n",
    "plt.legend(y)\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, z_dim):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.z_dim = z_dim\n",
    "        \n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, z_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, z_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(z_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        h1 = nn.functional.relu(self.fc1(x))\n",
    "        print(h1.shape)\n",
    "        mu, logvar = self.fc21(h1), self.fc22(h1)\n",
    "        print(mu.shape)\n",
    "        print(logvar.shape)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps*std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h3 = nn.functional.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.reshape(-1, self.input_dim).float())\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim, hidden_dim, num_classes):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Encoder layers\n",
    "        self.fc1 = nn.Linear(input_dim + num_classes, hidden_dim)\n",
    "        self.fc21 = nn.Linear(hidden_dim, latent_dim)\n",
    "        self.fc22 = nn.Linear(hidden_dim, latent_dim)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.fc3 = nn.Linear(latent_dim , hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, input_dim)\n",
    "        \n",
    "        # Activation function\n",
    "        self.activation = nn.ReLU()\n",
    "        \n",
    "    def encode(self, x, y):\n",
    "        # Concatenate input and target data\n",
    "        x = torch.cat([x, y], dim=1)\n",
    "        print(x.shape)\n",
    "        \n",
    "        # Pass through encoder network\n",
    "        x = self.activation(self.fc1(x))\n",
    "        #print(x.dtype)\n",
    "        mu = self.fc21(x)\n",
    "        #print(mu.dtype)\n",
    "        logvar = self.fc22(x)\n",
    "        #print(logvar.dtype)\n",
    "        return mu, logvar\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        # Sample from the reparameterization trick\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        #print(std.shape)\n",
    "        eps = torch.randn_like(std)\n",
    "        #print(eps.shape)\n",
    "        z = mu + eps * std\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z, y):\n",
    "        # Concate target / latent \n",
    "        z = torch.cat([z, y], dim=1)\n",
    "        print(z.shape)\n",
    "        # Pass through decoder network\n",
    "        z = self.activation(self.fc3(z))\n",
    "        recon = self.fc4(z)\n",
    "        #print(recon.shape)\n",
    "        return recon\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        mu, logvar = self.encode(x, y)\n",
    "        #print(mu.shape)\n",
    "        #print(logvar.shape)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        #print(z.shape)\n",
    "        recon = self.decode(z, y)\n",
    "        #print(recon.shape)\n",
    "        return recon, mu, logvar\n",
    "\n",
    "def multiclass_vae_loss(recon_x, x, mu, logvar):\n",
    "    # Reconstruction loss\n",
    "    BCE = nn.BCEWithLogitsLoss(reduction='sum')\n",
    "    recon_loss = BCE(recon_x, x) / x.size(0)\n",
    "    \n",
    "    # KL divergence loss\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    KLD /= x.size(0) * x.size(1)\n",
    "    \n",
    "    return recon_loss + KLD\n",
    "\n",
    "def train_multiclass_vae(model, train_loader, optimizer, num_epochs):\n",
    "    # Train the VAE for num_epochs epochs\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            recon, mu, logvar = model(data.float(),   target.float())\n",
    "            print(recon.shape)\n",
    "            print(mu.shape)\n",
    "            print(logvar.shape)\n",
    "            loss = multiclass_vae_loss(recon, data, mu, logvar)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    print('Epoch {}, Loss: {:.4f}'.format(epoch+1, total_loss / len(train_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the microbiome data and labels into PyTorch tensors\n",
    "data = torch.load(\"../Data/Tensors_objs/features.pt\")\n",
    "labels = torch.load(\"../Data/Tensors_objs/labels.pt\")\n",
    "data = torch.DoubleTensor(data)\n",
    "labels = labels.float()\n",
    "labels = labels.double()\n",
    "#labels = torch.DoubleTensor(labels)\n",
    "#nan_indices = torch.isnan(data)\n",
    "#data = torch.where(nan_indices, torch.tensor(0.0), data)\n",
    "\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(data, labels)\n",
    "# Define the dataset and dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([636, 150])"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 151])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10x151 and 15x10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [385], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[39m=\u001b[39m VAE(\u001b[39m10\u001b[39m,\u001b[39m2\u001b[39m, \u001b[39m10\u001b[39m,\u001b[39m5\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m train_multiclass_vae(model,dataloader,optimizer,\u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [367], line 83\u001b[0m, in \u001b[0;36mtrain_multiclass_vae\u001b[0;34m(model, train_loader, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, (data, target) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     82\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 83\u001b[0m     recon, mu, logvar \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mfloat(),   target\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m     84\u001b[0m     \u001b[39mprint\u001b[39m(recon\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     85\u001b[0m     \u001b[39mprint\u001b[39m(mu\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [367], line 56\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, y):\n\u001b[0;32m---> 56\u001b[0m     mu, logvar \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(x, y)\n\u001b[1;32m     57\u001b[0m     \u001b[39m#print(mu.shape)\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[39m#print(logvar.shape)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparameterize(mu, logvar)\n",
      "Cell \u001b[0;32mIn [367], line 28\u001b[0m, in \u001b[0;36mVAE.encode\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(x\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     27\u001b[0m \u001b[39m# Pass through encoder network\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactivation(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[1;32m     29\u001b[0m \u001b[39m#print(x.dtype)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m mu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc21(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10x151 and 15x10)"
     ]
    }
   ],
   "source": [
    "model = VAE(10,2, 10,5)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "train_multiclass_vae(model,dataloader,optimizer,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self, input_size, latent_size):\n",
    "        super(VAE, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.latent_size = latent_size\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_size*2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_size, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, input_size)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        h = self.encoder(x)\n",
    "        mu, log_var = torch.chunk(h, 2, dim=-1)\n",
    "        return mu, log_var\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        z = mu + eps*std\n",
    "        return z\n",
    "\n",
    "    def decode(self, z):\n",
    "        x_hat = self.decoder(z)\n",
    "        return x_hat\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, log_var = self.encode(x)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mu, log_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(x, x_hat, mu, log_var):\n",
    "    # Reconstruction error\n",
    "    recon_loss = F.mse_loss(x_hat, x, reduction='sum')\n",
    "\n",
    "    # KL divergence\n",
    "    kld_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "\n",
    "    # Total loss\n",
    "    total_loss = (recon_loss + kld_loss)\n",
    "\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [396], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     18\u001b[0m x \u001b[39m=\u001b[39m batch_data\n\u001b[0;32m---> 19\u001b[0m x_hat, mu, log_var \u001b[39m=\u001b[39m vae(x)\n\u001b[1;32m     21\u001b[0m loss \u001b[39m=\u001b[39m vae_loss(x, x_hat, mu, log_var)\n\u001b[1;32m     22\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn [394], line 41\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 41\u001b[0m     mu, log_var \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencode(x)\n\u001b[1;32m     42\u001b[0m     z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparameterize(mu, log_var)\n\u001b[1;32m     43\u001b[0m     x_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode(z)\n",
      "Cell \u001b[0;32mIn [394], line 26\u001b[0m, in \u001b[0;36mVAE.encode\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencode\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 26\u001b[0m     h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(x)\n\u001b[1;32m     27\u001b[0m     mu, log_var \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mchunk(h, \u001b[39m2\u001b[39m, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     28\u001b[0m     \u001b[39mreturn\u001b[39;00m mu, log_var\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "# Define the VAE model\n",
    "input_size = 16 # size of each input feature\n",
    "latent_size =2 # size of the latent variables\n",
    "vae = VAE(input_size, latent_size)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(vae.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 50# number of epochs\n",
    "batch_size =128 # size of each batch\n",
    "data_loader =  dataloader # torch.utils.data.DataLoader for your dataset\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for batch_idx, batch_data in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x = batch_data\n",
    "        x_hat, mu, log_var = vae(x)\n",
    "\n",
    "        loss = vae_loss(x, x_hat, mu, log_var)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, total_loss / len(data_loader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = nn.functional.cross_entropy(recon_x, x.reshape(-1, input_dim), reduction='sum')\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae1(model, eex, epochs, batch_size, learning_rate):\n",
    "    train_loader =  DataLoader(dataset, batch_size=20, shuffle=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_idx, eex in enumerate(train_loader):\n",
    "           \n",
    "            optimizer.zero_grad()\n",
    "            recon_batch, mu, logvar = model(data.float())\n",
    "            loss = loss_function(recon_batch, data.float(), mu, logvar)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print('Epoch: {} \\t Loss: {:.6f}'.format(epoch+1, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 150 # Define the size of your input data\n",
    "my_list = 2\n",
    "z_dim = 150 # Define the size of the latent space\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VAE(input_dim,my_list, z_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the microbiome data and labels into PyTorch tensors\n",
    "data = torch.load(\"../Data/Tensors_objs/features.pt\")\n",
    "labels = torch.load(\"../Data/Tensors_objs/labels.pt\")\n",
    "data = torch.DoubleTensor(data)\n",
    "labels = labels.float()\n",
    "labels = labels.double()\n",
    "#labels = torch.DoubleTensor(labels)\n",
    "nan_indices = torch.isnan(data)\n",
    "data = torch.where(nan_indices, torch.tensor(0.0), data)\n",
    "\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(data, labels)\n",
    "# Define the dataset and dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "VAE.forward() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [386], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_vae1(model, dataloader, \u001b[39m50\u001b[39;49m, \u001b[39m32\u001b[39;49m, \u001b[39m1e-4\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn [98], line 11\u001b[0m, in \u001b[0;36mtrain_vae1\u001b[0;34m(model, eex, epochs, batch_size, learning_rate)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39mfor\u001b[39;00m batch_idx, eex \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(train_loader):\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m     recon_batch, mu, logvar \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mfloat())\n\u001b[1;32m     12\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(recon_batch, data\u001b[39m.\u001b[39mfloat(), mu, logvar)\n\u001b[1;32m     13\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mTypeError\u001b[0m: VAE.forward() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "train_vae1(model, dataloader, 50, 32, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(VAE.state_dict(model), '../Model/vae_one_study2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Model and encode data\n",
    "VAE.load_state_dict(model, torch.load('vae_one_study2.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [104], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     z, _ \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mdecode(data\u001b[39m.\u001b[39mfloat())\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    z, _ = model.decode(data.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset and classes needed in this example:\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from itertools import product\n",
    "\n",
    "# Import Gaussian Naive Bayes classifier:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 1 0 2 1 0 1 4 4 1 1 2 0 4 0 3 1 3 1 1 1 1 3 1 3 3 4 0 4 1 0 3 4 2 1 1 1\n",
      " 1 2 1 3 1 3 4 2 1 3 1 2 2 3 0 3 3 0 1 1 0 4 1 1 1 1 1 3 1 1 0 1 4 3 1 1 1\n",
      " 1 1 1 2 4 1 0 1 4 4 4 4 2 1 1 1 1 0 3 1 4 1 1 4 4 1 1 0 3 4 4 1 1 4 0 1 1\n",
      " 1 2 1 4 1 0 3 4 3 4 3 0 4 3 2 1 4]\n",
      "1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into random train and test subsets:\n",
    "train, test, train_labels, test_labels = train_test_split(data, labels, test_size=0.2, random_state=5)\n",
    "\n",
    "# Initialize classifier:\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the classifier:\n",
    "classifier = gnb.fit(train, train_labels)\n",
    "# Make predictions with the classifier:\n",
    "predictive_labels = gnb.predict(test)\n",
    "print(predictive_labels)\n",
    "\n",
    "# Evaluate label (subsets) accuracy:\n",
    "print(accuracy_score(test_labels, predictive_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 4 3 4 4 3 4 0 1 1 1 1 4 1 1 0 0 0 2 4 1 1 4 1 1 1 1 1 1 1 1 2 4 1 4\n",
      " 1 3 0 1 1 0 0 4 0 3 3 1 2 1 3 1 1 1 4 1 1 0 1 0 1 1 0 1 1 0 1 0 4 0 4 1 2\n",
      " 4 1 1 3 1 1 4 1 1 1 1 4 3 4 1 3 4 3 0 2 3 4 2 3 2 1 1 1 1 2 0 1 1 4 1 1 1\n",
      " 1 3 3 1 1 4 0 1 3 1 1 1 1 2 1 1 1]\n",
      "0.9921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Split dataset into random train and test subsets:\n",
    "train, test, train_labels, test_labels = train_test_split(compined, labels, test_size=0.2, random_state=11)\n",
    "\n",
    "# Initialize classifier:\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train the classifier:\n",
    "classifier = gnb.fit(train, train_labels)\n",
    "# Make predictions with the classifier:\n",
    "predictive_labels = gnb.predict(test)\n",
    "print(predictive_labels)\n",
    "\n",
    "# Evaluate label (subsets) accuracy:\n",
    "print(accuracy_score(test_labels, predictive_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42, max_iter=1000)\n",
    "clf.fit(compined, labels)\n",
    "# Evaluate the classifier on the validation set\n",
    "y_val_pred = clf.predict(test)\n",
    "val_accuracy = accuracy_score(test_labels, y_val_pred)\n",
    "val_confusion_matrix = confusion_matrix(test_labels, y_val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 1.0000\n",
      "Validation confusion matrix:\n",
      "[[17  0  0  0  0]\n",
      " [ 0 66  0  0  0]\n",
      " [ 0  0  9  0  0]\n",
      " [ 0  0  0 15  0]\n",
      " [ 0  0  0  0 21]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Validation confusion matrix:\\n{val_confusion_matrix}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision boundaries and data points\n",
    "x_min, x_max = test.min() - 0.1, test.max() + 0.1\n",
    "y_min, y_max = test.min() - 0.1, test.max() + 0.1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n",
    "                     np.linspace(y_min, y_max, 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# first, find the indices of the points in class A and class B\n",
    "indices_A = np.where(labels == 1)[0]\n",
    "indices_B = np.where(labels == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,\n",
       "        55,  56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,\n",
       "        68,  69,  70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,\n",
       "        81,  82,  83,  84,  85,  86,  87,  88, 146, 147, 148, 149, 150,\n",
       "       151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163,\n",
       "       164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176,\n",
       "       177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189,\n",
       "       190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202,\n",
       "       203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215,\n",
       "       216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228,\n",
       "       229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241,\n",
       "       242, 243, 244, 344, 345, 346, 347, 348, 352, 353, 354, 355, 357,\n",
       "       358, 359, 360, 361, 362, 363, 364, 365, 366, 368, 369, 370, 371,\n",
       "       372, 373, 374, 376, 377, 378, 379, 381, 382, 383, 384, 385, 386,\n",
       "       389, 390, 391, 392, 393, 397, 398, 399, 402, 404, 405, 406, 408,\n",
       "       410, 411, 412, 414, 415, 417, 420, 422, 423, 424, 461, 462, 463,\n",
       "       464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476,\n",
       "       477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
       "       490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502,\n",
       "       503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515,\n",
       "       516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528,\n",
       "       529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541,\n",
       "       542])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data points (Tensors) in class A and class B\n",
    "points_A = data[indices_A]\n",
    "points_B = data[indices_B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  closest point in class B to the first point in class A\n",
    "point_A = points_A[0]\n",
    "distances = torch.norm(points_B - point_A, dim=1)\n",
    "min_distance = torch.min(distances)\n",
    "closest_point_B = points_B[torch.argmin(distances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The minimum Euclidean distance between a point in class A and a point in class B is 24.572020023521226.\n",
      "The closest point in class B to the first point in class A is tensor([0.0000, 0.0000, 0.1819, 0.0000, 0.0000, 0.0000, 0.0000, 0.2239, 0.2333,\n",
      "        0.1362, 0.1235, 0.0000, 0.0000, 0.0000, 0.1215, 0.1320, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.0000, 0.1500, 0.0000, 0.0119, 0.0000, 0.0000, 0.0726,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2151, 0.0000, 0.0000, 0.1345,\n",
      "        0.0000, 0.1855, 0.0000, 0.1912, 0.0000, 0.0000, 0.2760, 0.0000, 0.0666,\n",
      "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 2.2519, 0.0000, 0.0000, 1.2691,\n",
      "        0.0000, 0.0000, 0.0000, 2.5403, 0.0000, 1.4951, 1.4841, 1.2158, 3.4579,\n",
      "        0.0000, 0.2574, 1.5570, 0.0000, 3.4918, 1.1940, 0.0000, 0.0000, 0.1771,\n",
      "        0.0000, 0.0000, 1.9311, 1.8469, 4.2595, 2.4102, 1.9308, 0.0000, 1.5183,\n",
      "        4.4092, 0.0000, 0.4729, 0.0000, 0.2926, 2.7506, 0.0000, 0.0000, 2.1808,\n",
      "        6.7957, 3.5056, 2.4417, 0.0000, 0.0000, 0.1032, 0.8042, 0.0991, 0.1461,\n",
      "        3.3183, 0.0000, 1.9539, 1.0659, 0.0775, 0.0000, 0.4768, 0.0000, 0.0270,\n",
      "        0.0000, 1.5593, 3.4844, 1.9633, 0.3306, 0.0000, 0.0000, 0.0000, 1.8488,\n",
      "        0.0000, 1.3271, 0.0000, 0.0000, 0.0000, 0.0000, 1.9618, 0.0000, 3.0954,\n",
      "        1.7719, 0.0000, 2.6623, 1.8815, 0.0000, 0.0000, 0.1827, 0.0000, 0.0000,\n",
      "        0.0000, 0.0000, 0.3736, 0.5692, 2.3507, 0.0347, 0.0000, 3.6566, 1.9310,\n",
      "        0.0000, 0.0000, 2.7296, 2.5002, 0.0000, 1.0050], dtype=torch.float64).\n",
      "The difference between the two points is tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -1.9172,  0.0000,  0.0000, -1.8660, -1.4439,  0.0000,\n",
      "         0.0000, -0.4773,  0.0000,  1.4951, -2.9613,  1.2158,  3.4579,  0.0000,\n",
      "         0.2574, -5.1283,  0.0000,  3.2428, -3.5884,  0.0000,  0.0000, -4.5995,\n",
      "         0.0000, -1.2142,  1.9311, -3.1258,  4.2595,  2.4102,  1.9308,  0.0000,\n",
      "        -5.2664,  4.4092,  0.0000,  0.4729,  0.0000, -6.5822,  2.7506,  0.0000,\n",
      "        -4.6088,  2.1808,  6.7957,  3.5056, -3.3284,  0.0000,  0.0000, -2.8530,\n",
      "        -3.6366, -5.2729, -6.1247,  3.1598,  0.0000,  1.8872,  0.9012, -3.4233,\n",
      "        -3.2590, -0.3176,  0.0000, -2.7533, -1.9591,  0.7810,  3.4391,  1.8413,\n",
      "        -1.6831,  0.0000,  0.0000, -2.4847,  1.8488,  0.0000,  1.1764,  0.0000,\n",
      "         0.0000,  0.0000, -1.2193,  1.9618,  0.0000,  2.6741,  1.7719,  0.0000,\n",
      "         2.5285,  0.9513,  0.0000, -1.8964, -2.0705,  0.0000, -1.3737,  0.0000,\n",
      "        -2.2585, -0.9377,  0.3989,  1.8909, -3.2630, -3.2157,  3.6566,  1.5836,\n",
      "         0.0000, -2.3542,  2.6934,  2.2065,  0.0000,  0.9973],\n",
      "       dtype=torch.float64).\n"
     ]
    }
   ],
   "source": [
    "# calculate the difference between the two points\n",
    "difference = closest_point_B - point_A\n",
    "\n",
    "print(f\"The minimum Euclidean distance between a point in class A and a point in class B is {min_distance}.\")\n",
    "print(f\"The closest point in class B to the first point in class A is {closest_point_B}.\")\n",
    "print(f\"The difference between the two points is {difference}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indices = torch.where(torch.all(data == closest_point_B, axis=1))[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 1.9539, 1.0659, 0.0775, 0.0000, 0.4768, 0.0000, 0.0270, 0.0000,\n",
       "        1.5593, 3.4844, 1.9633, 0.3306, 0.0000, 0.0000, 0.0000, 1.8488, 0.0000,\n",
       "        1.3271, 0.0000, 0.0000, 0.0000, 0.0000, 1.9618, 0.0000, 3.0954, 1.7719,\n",
       "        0.0000, 2.6623, 1.8815, 0.0000, 0.0000, 0.1827, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.3736, 0.5692, 2.3507, 0.0347, 0.0000, 3.6566, 1.9310, 0.0000,\n",
       "        0.0000, 2.7296, 2.5002, 0.0000, 1.0050, 2.2519, 0.0000, 0.0000, 1.2691,\n",
       "        0.0000, 0.0000, 0.0000, 2.5403, 0.0000, 1.4951, 1.4841, 1.2158, 3.4579,\n",
       "        0.0000, 0.2574, 1.5570, 0.0000, 3.4918, 1.1940, 0.0000, 0.0000, 0.1771,\n",
       "        0.0000, 0.0000, 1.9311, 1.8469, 4.2595, 2.4102, 1.9308, 0.0000, 1.5183,\n",
       "        4.4092, 0.0000, 0.4729, 0.0000, 0.2926, 2.7506, 0.0000, 0.0000, 2.1808,\n",
       "        6.7957, 3.5056, 2.4417, 0.0000, 0.0000, 0.1032, 0.8042, 0.0991, 0.1461,\n",
       "        3.3183, 2.2519, 0.0000, 0.0000, 1.2691, 0.0000, 0.0000, 0.0000, 2.5403,\n",
       "        0.0000, 1.4951, 1.4841, 1.2158, 3.4579, 0.0000, 0.2574, 1.5570, 0.0000,\n",
       "        3.4918, 1.1940, 0.0000, 0.0000, 0.1771, 0.0000, 0.0000, 1.9311, 1.8469,\n",
       "        4.2595, 2.4102, 1.9308, 0.0000, 1.5183, 4.4092, 0.0000, 0.4729, 0.0000,\n",
       "        0.2926, 2.7506, 0.0000, 0.0000, 2.1808, 6.7957, 3.5056, 2.4417, 0.0000,\n",
       "        0.0000, 0.1032, 0.8042, 0.0991, 0.1461, 3.3183], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/wt/pl8gm0gs50d6vpk0nxfh07_h0000gn/T/ipykernel_20804/1601153969.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  single_tensor = torch.tensor(data[99])  # or any other single tensor\n"
     ]
    }
   ],
   "source": [
    "single_tensor = torch.tensor(data[99])  # or any other single tensor\n",
    "decoded_tensor = model.decode(single_tensor.unsqueeze(0).float())  # pass to the decoder of your VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "\n",
    "# compute Euclidean distances between decoded tensor and all original tensors\n",
    "distances = cdist(decoded_tensor.detach().numpy(), data.numpy(), metric='euclidean')\n",
    "\n",
    "# find index of the original tensor with the smallest distance\n",
    "index = torch.argmin(torch.from_numpy(distances))\n",
    "\n",
    "# select the original tensor with the smallest distance\n",
    "original_sample = dataset[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(465)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
